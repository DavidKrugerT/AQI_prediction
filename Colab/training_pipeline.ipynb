{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and installations"
      ],
      "metadata": {
        "id": "rzOohOpsQxj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kvjUQebh9udY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hopsworks"
      ],
      "metadata": {
        "id": "7Eu5kZZZduK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization"
      ],
      "metadata": {
        "id": "cfZSjwfXFWbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hopsworks"
      ],
      "metadata": {
        "id": "hJBMOZy3Q0Zc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfpd3d1umr-O"
      },
      "outputs": [],
      "source": [
        "import hopsworks\n",
        "\n",
        "project = hopsworks.login()\n",
        "\n",
        "fs = project.get_feature_store() "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_view = fs.get_feature_view(\n",
        "    name = 'air_quality_fv',\n",
        "    version = 1\n",
        ")"
      ],
      "metadata": {
        "id": "aOfZ9Fehm35L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX,testX,trainY,testY = feature_view.get_train_test_split(1)"
      ],
      "metadata": {
        "id": "YizRAVyAlpvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "Cj8fuTjx5IBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanData(X,Y):\n",
        "  try:\n",
        "    X = X.drop(columns=[\"date\",\"pm25\",\"pm10\",\"weathercode\",\"no2\",\"sunrise\",\"sunset\"])\n",
        "  except:\n",
        "    print(\"An exception occurred\")\n",
        "  notNa = X.isna().any(axis=1)\n",
        "  return X[~notNa],Y[~notNa]"
      ],
      "metadata": {
        "id": "Rjgv0ecwSIjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX,trainY = cleanData(trainX,trainY)\n",
        "trainX.head()"
      ],
      "metadata": {
        "id": "araVStBXbpQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformation"
      ],
      "metadata": {
        "id": "VdeKmoAgfbkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "AF7PqTC21qF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaledTrainX = scaler.fit_transform(trainX)\n",
        "print(scaler.mean_)\n",
        "print(scaler.var_)\n",
        "print(scaledTrainX)\n",
        "print(scaledTrainX.shape)"
      ],
      "metadata": {
        "id": "pwYrPOwDYFH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainY = np.ravel(trainY)"
      ],
      "metadata": {
        "id": "P3GqLo4BdUj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "hYpFVz121uDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testX,testY = cleanData(testX,testY)\n",
        "testX = scaler.transform(testX)\n",
        "testY = np.ravel(testY)"
      ],
      "metadata": {
        "id": "8IPYZzL414K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "Ubb9BRuJff58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GradientBoostingRegressor"
      ],
      "metadata": {
        "id": "JhncAFJJ05tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingRegressor()\n",
        "gb.fit(scaledTrainX, trainY)\n",
        "gb.score(testX,testY)\n",
        "gbPred = gb.predict(testX)\n",
        "gbRpred = np.rint(gbPred)\n",
        "mean_squared_error(testY, gbRpred)"
      ],
      "metadata": {
        "id": "L061qaA0Y6rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandomForest"
      ],
      "metadata": {
        "id": "mjvLr6GF1Nmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(max_depth=2, random_state=0)\n",
        "rf.fit(scaledTrainX, trainY)\n",
        "rf.score(testX,testY)\n",
        "rfPred = rf.predict(testX)\n",
        "rfRpred = np.rint(rfPred)\n",
        "mean_squared_error(testY, rfRpred)"
      ],
      "metadata": {
        "id": "S7SOBu3m1ePx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural network"
      ],
      "metadata": {
        "id": "FHX6haUN4SXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN = MLPRegressor(random_state=1, max_iter=500)\n",
        "NN.fit(scaledTrainX, trainY)\n",
        "NN.score(testX, testY)\n",
        "nnPred = NN.predict(testX)\n",
        "nnRpred = np.rint(nnPred)\n",
        "mean_squared_error(testY, nnRpred)"
      ],
      "metadata": {
        "id": "ooUF72yS4Wcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HyperParameter"
      ],
      "metadata": {
        "id": "RhlXenYGEiAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "def rf_evaluate(n_estimators, max_depth):\n",
        "    # Create the random forest object\n",
        "    rf = RandomForestRegressor(n_estimators=int(n_estimators), max_depth=int(max_depth))\n",
        "    \n",
        "    # Fit the model on the training data\n",
        "    rf.fit(scaledTrainX, trainY)\n",
        "    \n",
        "    # Make predictions on the test data\n",
        "    y_pred = rf.predict(testX)\n",
        "    rfRpred = np.rint(y_pred)\n",
        "    # Compute the accuracy score\n",
        "    return -mean_squared_error(testY, rfRpred)\n",
        "\n",
        "bo = BayesianOptimization(rf_evaluate, {'n_estimators': (50, 500), 'max_depth': (3, 400)})\n",
        "# Perform the optimization\n",
        "bo.maximize()\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(\"Best parameters: {}\".format(bo.max))\n",
        "print(\"Best score: {:.2f}\".format(bo.max['target']))"
      ],
      "metadata": {
        "id": "ZlVScPNjEhNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "def gb_evaluate(n_estimators, max_depth):\n",
        "    # Create the random forest object\n",
        "    #rf = RandomForestRegressor(n_estimators=int(n_estimators), max_depth=int(max_depth))\n",
        "    gb = GradientBoostingRegressor(n_estimators=int(n_estimators), max_depth=int(max_depth))\n",
        "    # Fit the model on the training data\n",
        "    gb.fit(scaledTrainX, trainY)\n",
        "    \n",
        "    # Make predictions on the test data\n",
        "    y_pred = gb.predict(testX)\n",
        "    gbRpred = np.rint(y_pred)\n",
        "    # Compute the accuracy score\n",
        "    return -mean_squared_error(testY, gbRpred)\n",
        "\n",
        "bo = BayesianOptimization(gb_evaluate, {'n_estimators': (50, 1000), 'max_depth': (3, 100)})\n",
        "# Perform the optimization\n",
        "bo.maximize()\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(\"Best parameters: {}\".format(bo.max))\n",
        "print(\"Best score: {:.2f}\".format(bo.max['target']))"
      ],
      "metadata": {
        "id": "jowhLHLENWR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Registry"
      ],
      "metadata": {
        "id": "3DlMbOoBkEvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf.predict(xx)"
      ],
      "metadata": {
        "id": "FO-M8fyamrk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mr = project.get_model_registry()"
      ],
      "metadata": {
        "id": "fnwqwWKAkFNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hsml.schema import Schema\n",
        "from hsml.model_schema import ModelSchema\n",
        "\n",
        "input_schema = Schema(testX)\n",
        "output_schema = Schema(testY)\n",
        "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
        "\n",
        "model_schema.to_dict()"
      ],
      "metadata": {
        "id": "H9xKXGU1kcv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(gb, 'model.pkl')"
      ],
      "metadata": {
        "id": "WXQ0XdF4kdZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = mr.sklearn.create_model(\n",
        "    name=\"gradient_boost_model\",\n",
        "    metrics={\"MSE\": \"178.32\"},\n",
        "    description=\"Gradient Boost Regressor without hyperparameter tuning\",\n",
        "    input_example=trainX.sample().to_numpy(),\n",
        "    model_schema=model_schema\n",
        ")\n",
        "\n",
        "model.save('model.pkl')"
      ],
      "metadata": {
        "id": "uJgTnN6fki9j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}